{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FeatureSelectRemoval.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8byim5qcJf4",
        "colab_type": "text"
      },
      "source": [
        "# Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTL8vn5gcJf5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNxK20_RcJf_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import stats \n",
        "\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "import sklearn.metrics as mx"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98_kbtQmcJgD",
        "colab_type": "code",
        "outputId": "ee928940-b284-4787-eca9-d944e2a05f9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "prefix = 'https://raw.githubusercontent.com/ptenteromano/Machine-Learning/master/data/'\n",
        "\n",
        "# Original data - used to get feature dictionary\n",
        "originalTrainUrl = prefix + 'census-income.data.csv'\n",
        "\n",
        "# Location of Mode data\n",
        "trainModeUrl = prefix + 'training_mode.csv'\n",
        "testModeUrl = prefix + 'test_mode.csv'\n",
        "\n",
        "# Location of Knn data\n",
        "trainKnnUrl = prefix + 'training_knn_Imputed.csv'\n",
        "testKnnUrl = prefix + 'test_knn_Imputed.csv'\n",
        "\n",
        "# Location of dropna data\n",
        "trainDropNaUrl = prefix + 'training_dropNa.csv'\n",
        "testDropNaUrl = prefix + 'test_dropNa.csv'\n",
        "\n",
        "# Taken from .names description file\n",
        "col_names = ['Age','Workclass','FinalWeight','Education','EducationNum','MaritalStatus','Occupation','Relationship','Race',\n",
        "         'Sex','CapitalGain','CapitalLoss','HoursPerWeek','NativeCountry','Label']\n",
        "\n",
        "# Original data\n",
        "trainOg = pd.read_csv(originalTrainUrl, names=col_names, header=None)\n",
        "\n",
        "# Mode data\n",
        "trainMode = pd.read_csv(trainModeUrl, index_col=0)\n",
        "testMode = pd.read_csv(testModeUrl, index_col=0)\n",
        "\n",
        "# Knn data\n",
        "trainKNN = pd.read_csv(trainKnnUrl, index_col=0)\n",
        "testKNN = pd.read_csv(testKnnUrl, index_col=0)\n",
        "\n",
        "# Dropna data\n",
        "trainDropNa = pd.read_csv(trainDropNaUrl, index_col=0)\n",
        "testDropNa = pd.read_csv(testDropNaUrl, index_col=0)\n",
        "\n",
        "print(len(trainMode) == len(trainKNN))\n",
        "print(len(testMode) == len(testKNN))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QWTgsSZcJgM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split data into features and labels\n",
        "def getX(df):\n",
        "    return df.iloc[:,:-1]\n",
        "\n",
        "def getLabel(df):\n",
        "    return df.iloc[:,-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8aH2__cpcJgP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TRAINING\n",
        "# Get feature data\n",
        "trainingOg_X = getX(trainOg)\n",
        "trainingMode_X = getX(trainMode)\n",
        "trainingKnn_X = getX(trainKNN)\n",
        "trainingDropNa_X = getX(trainDropNa)\n",
        "\n",
        "# Get labels\n",
        "trainingOg_Label = getLabel(trainOg)\n",
        "trainingMode_Label = getLabel(trainMode)\n",
        "trainingKnn_Label = getLabel(trainKNN)\n",
        "trainingDropNa_Label = getLabel(trainDropNa)\n",
        "\n",
        "# TESTING\n",
        "# Get feature data\n",
        "testMode_X = getX(testMode)\n",
        "testKnn_X = getX(testKNN)\n",
        "testDropNa_X = getX(testDropNa)\n",
        "\n",
        "# Get labels\n",
        "testMode_Label = getLabel(testMode)\n",
        "testKnn_Label = getLabel(testKNN)\n",
        "testDropNa_Label = getLabel(testDropNa)\n",
        "\n",
        "# Combine as unpackable lists to easily pass to functions\n",
        "# Stored as: [ Training Features, Training Label, testing Features, testing Label ]\n",
        "dataMode = [trainingMode_X, trainingMode_Label, testMode_X, testMode_Label]\n",
        "dataKnn = [ trainingKnn_X, trainingKnn_Label, testKnn_X, testKnn_Label ]\n",
        "dataDropNa = [ trainingDropNa_X, trainingDropNa_Label, testDropNa_X, testDropNa_Label ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJLge7N4cJgT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get Feature Dictionary - Mapping of Features -> new binary Feature columns\n",
        "def getFeatureDict(df):\n",
        "    # Get different types of data\n",
        "    num_attr = list(df.select_dtypes(include=['int']))\n",
        "    cat_attr = list(df.select_dtypes(include=['object']))\n",
        "    \n",
        "    # Prune the categorical values - 'Education is redudant'\n",
        "    for i,c in enumerate(cat_attr):\n",
        "        if 'Education' in c or 'Label' in c:\n",
        "            del cat_attr[i]\n",
        "    \n",
        "    # Prune Label just in case\n",
        "    for i,c in enumerate(num_attr):\n",
        "         if 'Label' in c:\n",
        "            del num_attr[i]\n",
        "    \n",
        "    # Init dictionary\n",
        "    featDict = {f: -1 for f in cat_attr}\n",
        "\n",
        "    # Map feature values to feature\n",
        "    for f in cat_attr:\n",
        "        featDict[f] = df[f].unique()\n",
        "    \n",
        "    # Remove bad feature values\n",
        "    for f in featDict:\n",
        "        for i,c in enumerate(featDict[f]):\n",
        "            try:\n",
        "                df[c].loc[0]\n",
        "            except: \n",
        "                if '?' in c:\n",
        "                    featDict[f] = np.delete(featDict[f], i)\n",
        "    \n",
        "    # Add numeric values as 1-1 map                    \n",
        "    for f in num_attr:\n",
        "        featDict[f] = f\n",
        "\n",
        "    return featDict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVitGi9EcJgW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# A dict of original { Features: FeatVals } \n",
        "featDict = getFeatureDict(trainOg)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nc1i-t4hcJgZ",
        "colab_type": "code",
        "outputId": "10076a4b-494c-4cdc-dcbb-7b6b8bb2b1c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "# Show the Number of values corresponding to the old categorical features\n",
        "for f in featDict:\n",
        "    if type(featDict[f]) is not str:\n",
        "        print(f, len(featDict[f]))\n",
        "    else:\n",
        "        print(f, ' - Continuous')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Workclass 8\n",
            "MaritalStatus 7\n",
            "Occupation 14\n",
            "Relationship 6\n",
            "Race 5\n",
            "Sex 2\n",
            "NativeCountry 41\n",
            "Age  - Continuous\n",
            "FinalWeight  - Continuous\n",
            "EducationNum  - Continuous\n",
            "CapitalGain  - Continuous\n",
            "CapitalLoss  - Continuous\n",
            "HoursPerWeek  - Continuous\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCXUbf_tcJgf",
        "colab_type": "text"
      },
      "source": [
        "### Classification Algorithms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SvoYF9MUcJgg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def KNN(trainingX, trainingY, testX):\n",
        "    knn= BaggingClassifier(base_estimator= KNeighborsClassifier())\n",
        "    knn.fit(trainingX, trainingY)\n",
        "    resultY= knn.predict(testX)\n",
        "    return resultY\n",
        "\n",
        "def LoReg(trainingX, trainingY, testX):\n",
        "    loreg= BaggingClassifier(base_estimator= LogisticRegression())\n",
        "    loreg.fit(trainingX, trainingY)\n",
        "    resultY= loreg.predict(testX)\n",
        "    return resultY\n",
        "\n",
        "def RForest(trainingX, trainingY, testX):\n",
        "    rf= BaggingClassifier(base_estimator= RandomForestClassifier())\n",
        "    rf.fit(trainingX, trainingY)\n",
        "    resultY= rf.predict(testX)\n",
        "    return resultY\n",
        "\n",
        "def SVM(trainingX, trainingY, testX):\n",
        "    with warnings.catch_warnings():\n",
        "        warnings.simplefilter(\"ignore\")\n",
        "        svm = BaggingClassifier(base_estimator = LinearSVC(max_iter=500))\n",
        "        svm.fit(trainingX, trainingY)\n",
        "        resultY= svm.predict(testX)\n",
        "    return resultY\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5Z5YeU7cJgj",
        "colab_type": "text"
      },
      "source": [
        "### Accuracy Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4HumcnucJgk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def knnAccuracy(trainingX, trainingY, testX, testY):\n",
        "    knntest = KNN(trainingX, trainingY, testX)\n",
        "    return mx.accuracy_score(knntest, testY)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gp5kgJLxcJgn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loRegAccuracy(trainingX, trainingY, testX, testY):\n",
        "    loregtest = LoReg(trainingX, trainingY, testX)\n",
        "    return mx.accuracy_score(loregtest, testY)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DrsFbg_ecJgs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rfAccuracy(trainingX, trainingY, testX, testY):\n",
        "    rf = RForest(trainingX, trainingY, testX)\n",
        "    return mx.accuracy_score(rf, testY)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NK9Pl2z4cJgu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def svmAccuracy(trainingX, trainingY, testX, testY):\n",
        "    svmtest = SVM(trainingX, trainingY, testX)\n",
        "    return mx.accuracy_score(svmtest, testY)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "piL4qULFcJgy",
        "colab_type": "text"
      },
      "source": [
        "### Test on full datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnHTtysFcJgz",
        "colab_type": "code",
        "outputId": "2bedf4dc-f597-4655-c27e-30463eaeead1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "print(\"KNN --> Mode Imputed: \" + str(knnAccuracy(*dataMode)))\n",
        "print(\"KNN --> Algo Imputed: \" + str(knnAccuracy(*dataKnn)))\n",
        "print(\"KNN --> Drop NA: \" + str(knnAccuracy(*dataDropNa)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "KNN --> Mode Imputed: 0.7794361525704809\n",
            "KNN --> Algo Imputed: 0.7782691480867269\n",
            "KNN --> Drop NA: 0.6810647915620291\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "2rcPorWwcJg4",
        "colab_type": "code",
        "outputId": "0ed32c8d-f949-4051-9347-981dd676ed2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "print(\"LoReg --> Mode Imputed: \" + str(loRegAccuracy(*dataMode)))\n",
        "print(\"LoReg --> Algo Imputed: \" + str(loRegAccuracy(*dataKnn)))\n",
        "print(\"LoReg --> Drop NA: \" + str(loRegAccuracy(*dataDropNa)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LoReg --> Mode Imputed: 0.7996437565260119\n",
            "LoReg --> Algo Imputed: 0.8000122842577237\n",
            "LoReg --> Drop NA: 0.7002941809571643\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "JN2xHvL3cJg8",
        "colab_type": "code",
        "outputId": "39d91aee-c73f-4dfe-ebe5-3162e1d3bb4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "print(\"Rand Forest --> Mode Imputed: \" + str(rfAccuracy(*dataMode)))\n",
        "print(\"Rand Forest --> Algo Imputed: \" + str(rfAccuracy(*dataKnn)))\n",
        "print(\"Rand Forest --> Drop NA: \" + str(rfAccuracy(*dataDropNa)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Rand Forest --> Mode Imputed: 0.8562741846323936\n",
            "Rand Forest --> Algo Imputed: 0.857379767827529\n",
            "Rand Forest --> Drop NA: 0.7449235847025902\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyEgvGtLcJhH",
        "colab_type": "code",
        "outputId": "361a158c-c61f-4aeb-dbaf-60370e677755",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "print(\"SVM --> Mode Imputed: \" + str(svmAccuracy(*dataMode)))\n",
        "print(\"SVM --> Algo Imputed: \" + str(svmAccuracy(*dataKnn)))\n",
        "print(\"SVM --> Drop NA: \" + str(svmAccuracy(*dataDropNa)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVM --> Mode Imputed: 0.7945457895706652\n",
            "SVM --> Algo Imputed: 0.7856397027209631\n",
            "SVM --> Drop NA: 0.7327975891511803\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpvFwKFMcJhQ",
        "colab_type": "text"
      },
      "source": [
        "# Feature Selection Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uqe4du8fcJhS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# accuracyMethod:(featureData, classData) => number\n",
        "def featureSelection(trainingX, trainingY, testX, testY, featureDict, accuracyMethod):\n",
        "    \n",
        "    # Best accuracy found\n",
        "    bestAccuracyAllTime = 0\n",
        "    \n",
        "    # KEYS in featDict - the actual feature\n",
        "    selectedFeatureLabels = []\n",
        "    \n",
        "    # VALUES in featDict - the tested feature values (which are columns of binary features)\n",
        "    selectedFeatureColumns = []\n",
        "    \n",
        "    iters = 0 \n",
        "    # Assure the algorithm does not select more features than there are available\n",
        "    while len(selectedFeatureColumns) < len(trainingX.columns):\n",
        "\n",
        "        # Best accuracy for the current iteration\n",
        "        bestAccuracy = 0\n",
        "        \n",
        "        # Best feature KEYS for the current iteration\n",
        "        bestFeatureLabels = []\n",
        "        \n",
        "        # Best feature VALUES for the current iteration\n",
        "        bestFeatureColumns = []\n",
        "        \n",
        "        iters += 1\n",
        "        \n",
        "        # Loop through all features\n",
        "        for f in featureDict:\n",
        "            \n",
        "            if f in selectedFeatureLabels:\n",
        "                # We've already added this feature to our selected list of features\n",
        "                continue\n",
        "                \n",
        "            # Features we're working with / testing\n",
        "            featureLabels = [ s for s in selectedFeatureLabels ]\n",
        "            featureLabels.append(f)\n",
        "            \n",
        "            # Get columns corresponding to that feature\n",
        "            if type(featureDict[f]) == str:\n",
        "                featureCols = [ featureDict[f] ]\n",
        "            else:\n",
        "                featureCols = list(featureDict[f])\n",
        "            \n",
        "            # Append what we already have to the test columns\n",
        "            for col in selectedFeatureColumns:\n",
        "                featureCols.append(col)\n",
        "            \n",
        "            # Store temporary feature labels\n",
        "            subsetTrainingX = trainingX[featureCols]\n",
        "            subsetTestingX = testX[featureCols]\n",
        "            \n",
        "            # Run the algorithm\n",
        "            accuracy = accuracyMethod(subsetTrainingX, trainingY, subsetTestingX, testY)\n",
        "            # print('\\t' + str(f) + ' ' + str(accuracy))\n",
        "            \n",
        "            # If the accuracy is the best accuracy from this iteration, update it\n",
        "            if accuracy > bestAccuracy:\n",
        "                bestAccuracy = accuracy\n",
        "                bestFeatureLabels = featureLabels\n",
        "                bestFeatureColumns = featureCols\n",
        "            \n",
        "        # Update the best accuracy and selected features with the best from this batch \n",
        "        if bestAccuracy > bestAccuracyAllTime:\n",
        "            bestAccuracyAllTime = bestAccuracy\n",
        "            selectedFeatureLabels = bestFeatureLabels\n",
        "            selectedFeatureColumns = bestFeatureColumns\n",
        "            print(iters, round(bestAccuracyAllTime, 4), selectedFeatureLabels)\n",
        "            \n",
        "        else:\n",
        "            # We've reached the best features we could have gotten\n",
        "            break\n",
        "    \n",
        "    # Return feature set and accuracy\n",
        "    return (selectedFeatureLabels, bestAccuracyAllTime)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVk6Uw7bcJhY",
        "colab_type": "text"
      },
      "source": [
        "## Callable functions - FS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfj7QGE4cJha",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# KNN feature Selection\n",
        "def knnFeatureSelection(trainingX, trainingY, testX, testY, featDict):\n",
        "    def accuracyMethod(trainingX, trainingY, testX, testY):\n",
        "\n",
        "        # Return accuracy using knn\n",
        "        return knnAccuracy(trainingX, trainingY, testX, testY)\n",
        "    \n",
        "    return featureSelection(trainingX, trainingY, testX, testY, featDict, accuracyMethod)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MfsoagtcJhe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Logistic Regression feature Selection\n",
        "def loRegFeatureSelection(trainingX, trainingY, testX, testY, featDict):\n",
        "    def accuracyMethod(trainingX, trainingY, testX, testY):\n",
        "\n",
        "        # Return accuracy using loReg\n",
        "        return loRegAccuracy(trainingX, trainingY, testX, testY)\n",
        "    \n",
        "    return featureSelection(trainingX, trainingY, testX, testY, featDict, accuracyMethod)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68IjzXMwcJhg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Random Forest feature Selection\n",
        "def rfFeatureSelection(trainingX, trainingY, testX, testY, featDict):\n",
        "    def accuracyMethod(trainingX, trainingY, testX, testY):\n",
        "\n",
        "        # Return accuracy using random forest\n",
        "        return rfAccuracy(trainingX, trainingY, testX, testY)\n",
        "    \n",
        "    return featureSelection(trainingX, trainingY, testX, testY, featDict, accuracyMethod)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzBkl26bcJhj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# SVM feature Selection\n",
        "def svmFeatureSelection(trainingX, trainingY, testX, testY, featDict):\n",
        "    def accuracyMethod(trainingX, trainingY, testX, testY):\n",
        "\n",
        "        # Return accuracy using knn\n",
        "        return svmAccuracy(trainingX, trainingY, testX, testY)\n",
        "    \n",
        "    return featureSelection(trainingX, trainingY, testX, testY, featDict, accuracyMethod)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZwgNaLrcJhm",
        "colab_type": "text"
      },
      "source": [
        "### Running Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hd7dFqotcJhn",
        "colab_type": "code",
        "outputId": "2f42495e-361f-4d81-b0ab-1f00baa1f5c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        }
      },
      "source": [
        "# LoReg Feature Selection using the data imputed with knn values\n",
        "loregSetFS_dataKnn, loregAccuracyFS_dataKnn = loRegFeatureSelection(*dataKnn, featDict)\n",
        "print(\"Knn-Done\\n\")\n",
        "loregSetFS_dataMode, loregAccuracyFS_dataMode = loRegFeatureSelection(*dataMode, featDict)\n",
        "print(\"Mode-Done\\n\")\n",
        "loregSetFS_dataDropNa, loregAccuracyFS_dataDropNa = loRegFeatureSelection(*dataDropNa, featDict)\n",
        "print(\"DropNA-Done\\n\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 0.8013 ['CapitalGain']\n",
            "2 0.8121 ['CapitalGain', 'CapitalLoss']\n",
            "3 0.8121 ['CapitalGain', 'CapitalLoss', 'NativeCountry']\n",
            "Done\n",
            "\n",
            "1 0.8007 ['CapitalGain']\n",
            "2 0.8098 ['CapitalGain', 'CapitalLoss']\n",
            "3 0.8105 ['CapitalGain', 'CapitalLoss', 'Relationship']\n",
            "4 0.8433 ['CapitalGain', 'CapitalLoss', 'Relationship', 'EducationNum']\n",
            "5 0.8498 ['CapitalGain', 'CapitalLoss', 'Relationship', 'EducationNum', 'Occupation']\n",
            "6 0.8512 ['CapitalGain', 'CapitalLoss', 'Relationship', 'EducationNum', 'Occupation', 'Workclass']\n",
            "7 0.8519 ['CapitalGain', 'CapitalLoss', 'Relationship', 'EducationNum', 'Occupation', 'Workclass', 'Race']\n",
            "Done\n",
            "\n",
            "1 0.7563 ['Workclass']\n",
            "2 0.7673 ['Workclass', 'Relationship']\n",
            "3 0.815 ['Workclass', 'Relationship', 'Occupation']\n",
            "4 0.8167 ['Workclass', 'Relationship', 'Occupation', 'NativeCountry']\n",
            "5 0.8173 ['Workclass', 'Relationship', 'Occupation', 'NativeCountry', 'Race']\n",
            "6 0.8178 ['Workclass', 'Relationship', 'Occupation', 'NativeCountry', 'Race', 'MaritalStatus']\n",
            "Done\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIFL1d9-cadK",
        "colab_type": "code",
        "outputId": "ef496d6b-7635-46cd-f8a1-154f823b4be3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        }
      },
      "source": [
        "# Random Forest Feature Selection using the data imputed with knn values\n",
        "rfSetFS_dataKnn, rfAccuracyFS_dataKnn = rfFeatureSelection(*dataKnn, featDict)\n",
        "print(\"Knn-Done\\n\")\n",
        "rfSetFS_dataMode, rfAccuracyFS_dataMode = rfFeatureSelection(*dataMode, featDict)\n",
        "print(\"Mode-Done\\n\")\n",
        "rfSetFS_dataDropNa, rfAccuracyFS_dataDropNa = rfFeatureSelection(*dataDropNa, featDict)\n",
        "print(\"DropNa-Done\\n\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 0.813 ['CapitalGain']\n",
            "2 0.8342 ['CapitalGain', 'CapitalLoss']\n",
            "3 0.8364 ['CapitalGain', 'CapitalLoss', 'EducationNum']\n",
            "4 0.8605 ['CapitalGain', 'CapitalLoss', 'EducationNum', 'MaritalStatus']\n",
            "Done\n",
            "\n",
            "1 0.8133 ['CapitalGain']\n",
            "2 0.8339 ['CapitalGain', 'CapitalLoss']\n",
            "3 0.8364 ['CapitalGain', 'CapitalLoss', 'EducationNum']\n",
            "4 0.8607 ['CapitalGain', 'CapitalLoss', 'EducationNum', 'MaritalStatus']\n",
            "Done\n",
            "\n",
            "1 0.7563 ['Workclass']\n",
            "2 0.7668 ['Workclass', 'Relationship']\n",
            "3 0.8195 ['Workclass', 'Relationship', 'Occupation']\n",
            "4 0.8256 ['Workclass', 'Relationship', 'Occupation', 'NativeCountry']\n",
            "5 0.829 ['Workclass', 'Relationship', 'Occupation', 'NativeCountry', 'Race']\n",
            "6 0.8299 ['Workclass', 'Relationship', 'Occupation', 'NativeCountry', 'Race', 'MaritalStatus']\n",
            "7 0.8314 ['Workclass', 'Relationship', 'Occupation', 'NativeCountry', 'Race', 'MaritalStatus', 'Sex']\n",
            "Done\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gv1GUNdcbD9",
        "colab_type": "code",
        "outputId": "e713ecf7-d498-4cad-bc93-6f7ca0fad262",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "# SVM Feature Selection using the data imputed with knn values\n",
        "svmSetFS_dataKnn, svmAccuracyFS_dataKnn = svmFeatureSelection(*dataKnn, featDict)\n",
        "print(\"Knn-Done\\n\")\n",
        "svmSetFS_dataMode, svmAccuracyFS_dataMode = svmFeatureSelection(*dataMode, featDict)\n",
        "print(\"Mode-Done\\n\")\n",
        "svmSetFS_dataDropNa, svmAccuracyFS_dataDropNa = svmFeatureSelection(*dataDropNa, featDict)\n",
        "print(\"DropNa-Done\\n\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 0.7951 ['CapitalGain']\n",
            "2 0.7991 ['CapitalGain', 'NativeCountry']\n",
            "3 0.8015 ['CapitalGain', 'NativeCountry', 'HoursPerWeek']\n",
            "Knn-Done\n",
            "\n",
            "1 0.8023 ['CapitalGain']\n",
            "Mode-Done\n",
            "\n",
            "1 0.7563 ['Workclass']\n",
            "2 0.7671 ['Workclass', 'Relationship']\n",
            "3 0.8134 ['Workclass', 'Relationship', 'Occupation']\n",
            "4 0.8159 ['Workclass', 'Relationship', 'Occupation', 'Race']\n",
            "5 0.8173 ['Workclass', 'Relationship', 'Occupation', 'Race', 'NativeCountry']\n",
            "DropNa-Done\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IT1SxR9wcb4u",
        "colab_type": "code",
        "outputId": "e2bad02b-596c-4fc9-e757-d248cac1fd7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "# KNN Feature Selection using the data imputed with knn values\n",
        "knnSetFS_dataKnn, knnAccuracyFS_dataKnn = knnFeatureSelection(*dataKnn, featDict)\n",
        "print(\"Knn-Done\\n\")\n",
        "knnSetFS_dataMode, knnAccuracyFS_dataMode = knnFeatureSelection(*dataMode, featDict)\n",
        "print(\"Mode-Done\\n\")\n",
        "knnSetFS_dataDropNa, knnAccuracyFS_dataDropNa = knnFeatureSelection(*dataDropNa, featDict)\n",
        "print(\"DropNa-Done\\n\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 0.813 ['CapitalGain']\n",
            "2 0.8335 ['CapitalGain', 'CapitalLoss']\n",
            "3 0.8339 ['CapitalGain', 'CapitalLoss', 'Relationship']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cprORLBcJhr",
        "colab_type": "text"
      },
      "source": [
        "# Feature Removal Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqpxr3vXcJhs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# accuracyMethod:(featureData, classData) => number\n",
        "def featureRemoval(trainingX, trainingY, testX, testY, featureDict, accuracyMethod):\n",
        "    \n",
        "    # Best accuracy found\n",
        "    bestAccuracyAllTime = 0\n",
        "        \n",
        "    # KEYS in featDict - the actual feature\n",
        "    selectedFeatureLabels = list(featureDict.keys())\n",
        "    \n",
        "    # VALUES in featDict - the tested feature values (which are columns of binary features)\n",
        "    selectedFeatureColumns = list(trainingX.columns)\n",
        "\n",
        "    # Assure the algorithm does not select more features than there are available\n",
        "    while len(selectedFeatureLabels) > 0:\n",
        "\n",
        "        # Best accuracy for the current iteration\n",
        "        bestAccuracy = 0\n",
        "        \n",
        "        # Best features KEYS for the current iteration\n",
        "        bestFeatureLabels = selectedFeatureLabels\n",
        "        \n",
        "        # Best features VALUES for the current iteration\n",
        "        bestFeatureColumns = selectedFeatureColumns\n",
        "        \n",
        "        # Loop through all features\n",
        "        for f in featureDict:\n",
        "            \n",
        "            if f not in selectedFeatureLabels:\n",
        "                # We've already removed this feature\n",
        "                continue\n",
        "                \n",
        "            # Features we're working with / testing - remove f from labels\n",
        "            featureLabels = [ s for s in selectedFeatureLabels if s is not f]\n",
        "                                \n",
        "            # Remove this feature from the test columns\n",
        "            for col in selectedFeatureColumns:\n",
        "                if col not in featDict[f]:\n",
        "                    featureCols.append(col)\n",
        "            \n",
        "            # Store temporary feature labels\n",
        "            subsetTrainingX = trainingX[featureCols]\n",
        "            subsetTestingX = testX[featureCols]\n",
        "            \n",
        "            # Run accuracy test\n",
        "            accuracy = accuracyMethod(subsetTrainingX, trainingY, subsetTestingX, testY)\n",
        "            print('\\t' + str(f) + ' ' + str(accuracy))\n",
        "            \n",
        "            # If the accuracy is the best accuracy from this iteration, update it\n",
        "            if accuracy > bestAccuracy:\n",
        "                bestAccuracy = accuracy\n",
        "                bestFeatureLabels = featureLabels\n",
        "                bestFeatureColumns = featureCols\n",
        "            \n",
        "        # Update the best accuracy and selected features with the best from this batch \n",
        "        if bestAccuracy > bestAccuracyAllTime:\n",
        "            bestAccuracyAllTime = bestAccuracy\n",
        "            selectedFeatureLabels = bestFeatureLabels\n",
        "            selectedFeatureColumns = bestFeatureColumns\n",
        "            print(round(bestAccuracyAllTime, 4), selectedFeatureLabels)\n",
        "            \n",
        "        else:\n",
        "            # We've reached the best features we could have gotten\n",
        "            break\n",
        "    \n",
        "    return (selectedFeatureLabels, bestAccuracyAllTime)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NDhF3bkcJhw",
        "colab_type": "text"
      },
      "source": [
        "## Callable functions - FR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkVpGInycJhz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# KNN feature Removal\n",
        "def knnFeatureRemoval(trainingX, trainingY, testX, testY, featDict):\n",
        "    def accuracyMethod(trainingX, trainingY, testX, testY):\n",
        "\n",
        "        # Return accuracy using knn\n",
        "        return knnAccuracy(trainingX, trainingY, testX, testY)\n",
        "    \n",
        "    return featureRemoval(trainingX, trainingY, testX, testY, featDict, accuracyMethod)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8m_T64JcJh2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Logistic Regression feature Removal\n",
        "def loRegFeatureRemoval(trainingX, trainingY, testX, testY, featDict):\n",
        "    def accuracyMethod(trainingX, trainingY, testX, testY):\n",
        "\n",
        "        # Return accuracy using loReg\n",
        "        return loRegAccuracy(trainingX, trainingY, testX, testY)\n",
        "    \n",
        "    return featureRemoval(trainingX, trainingY, testX, testY, featDict, accuracyMethod)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxJTZQ3ScJh6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Random Forest feature Removal\n",
        "def rfFeatureRemoval(trainingX, trainingY, testX, testY, featDict):\n",
        "    def accuracyMethod(trainingX, trainingY, testX, testY):\n",
        "\n",
        "        # Return accuracy using random forest\n",
        "        return rfAccuracy(trainingX, trainingY, testX, testY)\n",
        "    \n",
        "    return featureRemoval(trainingX, trainingY, testX, testY, featDict, accuracyMethod)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcKfAgMOcJh_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# SVM feature Removal\n",
        "def svmFeatureRemoval(trainingX, trainingY, testX, testY, featDict):\n",
        "    def accuracyMethod(trainingX, trainingY, testX, testY):\n",
        "\n",
        "        # Return accuracy using knn\n",
        "        return svmAccuracy(trainingX, trainingY, testX, testY)\n",
        "    \n",
        "    return featureRemoval(trainingX, trainingY, testX, testY, featDict, accuracyMethod)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXWjxE07cJiC",
        "colab_type": "text"
      },
      "source": [
        "### Running Feature Removal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUBm9ejscJiD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# LoReg Feature Removal using the data imputed with knn values\n",
        "loregSetFR_dataKnn, loregAccuracyFR_dataKnn = loRegFeatureRemoval(*dataKnn, featDict)\n",
        "print(\"Knn-Done\\n\")\n",
        "loregSetFR_dataMode, loregAccuracyFR_dataMode = loRegFeatureRemoval(*dataMode, featDict)\n",
        "print(\"Mode-Done\\n\")\n",
        "loregSetFR_dataDropNa, loregAccuracyFR_dataDropNa = loRegFeatureRemoval(*dataDropNa, featDict)\n",
        "print(\"DropNA-Done\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sCJEczD2Rve",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Random Forest Feature Removal using the data imputed with knn values\n",
        "rfSetFR_dataKnn, rfAccuracyFR_dataKnn = rfFeatureRemoval(*dataKnn, featDict)\n",
        "print(\"Knn-Done\\n\")\n",
        "rfSetFR_dataMode, rfAccuracyFR_dataMode = rfFeatureRemoval(*dataMode, featDict)\n",
        "print(\"Mode-Done\\n\")\n",
        "rfSetFR_dataDropNa, rfAccuracyFR_dataDropNa = rfFeatureRemoval(*dataDropNa, featDict)\n",
        "print(\"DropNA-Done\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkIvX_0g2SZI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# SVM Feature Removal using the data imputed with knn values\n",
        "svmSetFR_dataKnn, svmAccuracyFR_dataKnn = svmFeatureRemoval(*dataKnn, featDict)\n",
        "print(\"Knn-Done\\n\")\n",
        "svmSetFR_dataMode, svmAccuracyFR_dataMode = svmFeatureRemoval(*dataMode, featDict)\n",
        "print(\"Mode-Done\\n\")\n",
        "svmSetFR_dataDropNa, svmAccuracyFR_dataDropNa = svmFeatureRemoval(*dataDropNa, featDict)\n",
        "print(\"DropNA-Done\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r30HqgmP2S__",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# KNN Feature Removal using the data imputed with knn values\n",
        "knnSetFR_dataKnn, knnAccuracyFR_dataKnn = knnFeatureRemoval(*dataKnn, featDict)\n",
        "print(\"Knn-Done\\n\")\n",
        "knnSetFR_dataMode, knnAccuracyFR_dataMode = knnFeatureRemoval(*dataMode, featDict)\n",
        "print(\"Mode-Done\\n\")\n",
        "knnSetFR_dataDropNa, knnAccuracyFR_dataDropNa = knnFeatureRemoval(*dataDropNa, featDict)\n",
        "print(\"DropNA-Done\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZY6HddC3HtN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}